{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d90b2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from common.util import im2col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6804194e",
   "metadata": {},
   "source": [
    "# 합성곱\n",
    "\n",
    "가까이 있는 원소들의 관계를 모델에 포함시킬 수 있다.\n",
    "필터의 각 원소에 대응되는 입력 데이터의 원소 곱의 전체 합이 출력된다.\n",
    "\n",
    "## 합성곱 계층\n",
    "1. 패딩\n",
    "입력 데이터의 주변 값을 임의의 특정 값으로 채워 놓는다.\n",
    "출력 크기를 조정하기 위해 사용한다.\n",
    "\n",
    "2. 스트라이드\n",
    "필터가 적용되는 간격을 의미한다.\n",
    "\n",
    "출력크기 계산 하는 방법\n",
    "$$ OH = \\frac{H+2P-FH}{S} + 1 $$\n",
    "$$ OW = \\frac{W+2P-FW}{S} + 1 $$\n",
    "\n",
    "# 3 차원 데이터 합성곱 연산\n",
    "채널마다 입력데이터와 필터의 합성곱 연산을 수행하고, 결과를 모두 더해서 하나의 출력값을 만든다.\n",
    "\n",
    "**입력 데이터의 채널 수 = 필터의 채널 수**\n",
    "\n",
    "필터의 가중치 데이터는 4차원 데이터, (출력 채널 수, 입력 채널 수, 높이, 너비)\n",
    "\n",
    "## 풀링 계층\n",
    "최대 풀링, 평균 풀링\n",
    "\n",
    "풀링에서 윈도우 크기와 스트라이드는 같은 값으로 설정하는 것이 일반적."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "435d1b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 75)\n",
      "(90, 75)\n"
     ]
    }
   ],
   "source": [
    "#img2col 사용\n",
    "x1 = np.random.rand(1, 3, 7, 7)\n",
    "col1 = im2col(x1, 5, 5, stride=1, pad=0)\n",
    "print(col1.shape)\n",
    "\n",
    "x2 = np.random.rand(10, 3, 7, 7)\n",
    "col2 = im2col(x2, 5, 5, stride=1, pad=0)\n",
    "print(col2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1417d63c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15,  7,  3],\n",
       "       [ 3,  7, 19],\n",
       "       [ 5,  6,  4]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array([[[5, 7, 2], [3, 2, 8], [1, 6, 4]], [[15, 4, 3], [1, 7, 19], [5, 4, 2]]])\n",
    "np.max(test, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87e1aae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.layers import *\n",
    "from common.util import *\n",
    "from collections import OrderedDict\n",
    "\n",
    "class SimpleConvNet:\n",
    "  def __init__(\n",
    "      self, \n",
    "      input_dim=(1, 28, 28), \n",
    "      conv_param={'filter_num': 30, 'filter_size':5, 'pad': 0, 'stride': 1},\n",
    "      hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "    filter_num = conv_param['filter_num']\n",
    "    filter_size = conv_param['filter_size']\n",
    "    filter_pad = conv_param['pad']\n",
    "    filter_stride = conv_param['stride']\n",
    "    input_size = input_dim[1]\n",
    "    conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "    pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
    "\n",
    "    self.params = {}\n",
    "    self.params['W1'] = weight_init_std * np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "    self.params['b1'] = np.zeros(filter_num)\n",
    "    self.params['W2'] = weight_init_std * np.random.randn(pool_output_size, hidden_size)\n",
    "    self.params['b2'] = np.zeros(hidden_size)\n",
    "    self.params['W3'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "    self.params['b3'] = np.zeros(output_size)\n",
    "\n",
    "    self.layers = OrderedDict()\n",
    "    self.layers['Conv1'] = Convolution(self.params['W1'], \n",
    "                                       self.params['b1'], \n",
    "                                       conv_param['stride'], \n",
    "                                       conv_param['pad'])\n",
    "    self.layers['Relu1'] = Relu()\n",
    "    self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "    self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
    "    self.layers['Relu2'] = Relu()\n",
    "    self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "    \n",
    "    self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "  def predict(self, x):\n",
    "    for layer in self.layers.values():\n",
    "      x = layer.forward(x)\n",
    "    return x\n",
    "\n",
    "  def loss(self, x, t):\n",
    "    y = self.predict(x)\n",
    "    return self.last_layer.forward(y, t)\n",
    "  \n",
    "  def accuracy(self, x, t, batch_size=100):\n",
    "    if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "    \n",
    "    acc = 0.0\n",
    "    \n",
    "    for i in range(int(x.shape[0] / batch_size)):\n",
    "        tx = x[i*batch_size:(i+1)*batch_size]\n",
    "        tt = t[i*batch_size:(i+1)*batch_size]\n",
    "        y = self.predict(tx)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        acc += np.sum(y == tt) \n",
    "    \n",
    "    return acc / x.shape[0]\n",
    "  \n",
    "  def gradient(self, x, t):\n",
    "    self.loss(x, t)\n",
    "\n",
    "    dout = 1\n",
    "    dout = self.last_layer.backward(dout)\n",
    "\n",
    "    layers = list(self.layers.values())\n",
    "    layers.reverse()\n",
    "    for layer in layers:\n",
    "      dout = layer.backward(dout)\n",
    "\n",
    "    grads = {}\n",
    "    grads['W1'] = self.layers['Conv1'].dW\n",
    "    grads['b1'] = self.layers['Conv1'].db\n",
    "    grads['W2'] = self.layers['Affine1'].dW\n",
    "    grads['b2'] = self.layers['Affine1'].db\n",
    "    grads['W3'] = self.layers['Affine2'].dW\n",
    "    grads['b3'] = self.layers['Affine2'].db\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f618c3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.3000481139309024\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SimpleConvNet' object has no attribute 'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     19\u001b[39m network = SimpleConvNet(input_dim=(\u001b[32m1\u001b[39m,\u001b[32m28\u001b[39m,\u001b[32m28\u001b[39m), \n\u001b[32m     20\u001b[39m                         conv_param = {\u001b[33m'\u001b[39m\u001b[33mfilter_num\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m30\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfilter_size\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m5\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mpad\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mstride\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1\u001b[39m},\n\u001b[32m     21\u001b[39m                         hidden_size=\u001b[32m100\u001b[39m, output_size=\u001b[32m10\u001b[39m, weight_init_std=\u001b[32m0.01\u001b[39m)\n\u001b[32m     23\u001b[39m trainer = Trainer(network, x_train, t_train, x_test, t_test,\n\u001b[32m     24\u001b[39m                   epochs=max_epochs, mini_batch_size=\u001b[32m100\u001b[39m,\n\u001b[32m     25\u001b[39m                   optimizer=\u001b[33m'\u001b[39m\u001b[33mAdam\u001b[39m\u001b[33m'\u001b[39m, optimizer_param={\u001b[33m'\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.001\u001b[39m},\n\u001b[32m     26\u001b[39m                   evaluate_sample_num_per_epoch=\u001b[32m1000\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# 매개변수 보존\u001b[39;00m\n\u001b[32m     30\u001b[39m network.save_params(\u001b[33m\"\u001b[39m\u001b[33mparams.pkl\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/learning_dl/7_CNN/../common/trainer.py:72\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.max_iter):\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m     test_acc = \u001b[38;5;28mself\u001b[39m.network.accuracy(\u001b[38;5;28mself\u001b[39m.x_test, \u001b[38;5;28mself\u001b[39m.t_test)\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/learning_dl/7_CNN/../common/trainer.py:62\u001b[39m, in \u001b[36mTrainer.train_step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     59\u001b[39m     x_train_sample, t_train_sample = \u001b[38;5;28mself\u001b[39m.x_train[:t], \u001b[38;5;28mself\u001b[39m.t_train[:t]\n\u001b[32m     60\u001b[39m     x_test_sample, t_test_sample = \u001b[38;5;28mself\u001b[39m.x_test[:t], \u001b[38;5;28mself\u001b[39m.t_test[:t]\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m train_acc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccuracy\u001b[49m(x_train_sample, t_train_sample)\n\u001b[32m     63\u001b[39m test_acc = \u001b[38;5;28mself\u001b[39m.network.accuracy(x_test_sample, t_test_sample)\n\u001b[32m     64\u001b[39m \u001b[38;5;28mself\u001b[39m.train_acc_list.append(train_acc)\n",
      "\u001b[31mAttributeError\u001b[39m: 'SimpleConvNet' object has no attribute 'accuracy'"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from common.trainer import Trainer\n",
    "\n",
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 시간이 오래 걸릴 경우 데이터를 줄인다.\n",
    "#x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "#x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 20\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# 매개변수 보존\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "# 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
