import numpy as np

from common.functions import softmax, cross_entropy_error, sigmoid
from util import im2col

class Relu:
  def __init__(self):
    self.mask = None

  def forward(self, x):
    self.mask = (x <= 0)
    out = x.copy()
    out[self.mask] = 0

    return out
  
  def backward(self, dout):
    dout[self.mask] = 0
    dx = dout

    return dx

class Sigmoid:
  def __init__(self):
    self.out = None

  def forward(self, x):
    out = 1 / sigmoid(x)
    self.out = out

    return out
  
  def backward(self, dout):
    dx = dout * (1.0 - self.out) * self.out

    return dx
  
class Affine:
  def __init__(self, W, b):
    self.W = W
    self.b = b
    self.x = None
    self.original_x_shape = None
    self.dW = None
    self.db = None

  def forward(self, x):
    self.original_x_shape = x.shape
    x = x.reshape(x.shape[0], -1)
    self.x = x
    out = np.dot(x, self.W) + self.b

    return out
  
  def backward(self, dout):
    dx = np.dot(dout, self.W.T)
    self.dW = np.dot(self.x.T, dout)
    self.db = np.sum(dout, axis=0)

    dx = dx.reshape(*self.original_x_shape)
    return dx
  
class SoftmaxWithLoss:
  def __init__(self):
    self.loss = None
    self.y = None
    self.t = None

  def forward(self, x, t):
    self.t = t
    self.y = softmax(x)
    self.loss = cross_entropy_error(self.y, self.t)
    return self.loss
  
  def backward(self, dout=1):
    batch_size = self.t.shape[0]
    if self.t.size == self.y.size:
      dx = (self.y - self.t) / batch_size
    else:
      dx = self.y.copy()
      dx[np.arange(batch_size), self.t] -= 1
      dx = dx / batch_size

    return dx
  
# class Convolution:
#   def __init__(self, W, b, stride=1, pad=0):
#     self.W = W
#     self.b = b
#     self.stride = stride
#     self.pad = pad

#   def forward(self, x):
#     FN, C, FH, FW = self.W.shape
#     N, C, H, W = x.shape

#     out_h = int(1 + (H + 2 * self.pad - FH) / self.stride)
#     out_w = int(1 + (W + 2 * self.pad - FW) / self.stride)

#     col = im2col(x, FH, FW, self.stride, self.pad)
#     col_W = self.W.reshape(FN, -1).T
#     out = np.dot(col, col_W) + self.b

#     out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)

#     return out
  
# class Pooling:
#   def __init__(self, pool_h, pool_w, stride=1, pad=0):
#     self.pool_h = pool_h
#     self.pool_w = pool_w
#     self.stride = stride
#     self.pad = pad

#   def forward(self, x):
#     N, C, H, W = x.shape
#     out_h = int(1 + (H - self.pool_h) / self.stride)
#     out_w = int(1 + (H - self.pool_w) / self.stride)

#     col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)
#     col = col.reshape(-1, self.pool_h * self.pool_w)

#     out = np.max(col, axis=1)

#     out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)

#     return out